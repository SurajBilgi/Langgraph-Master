{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x118db9ed0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11c571d50> root_client=<openai.OpenAI object at 0x118dbb520> root_async_client=<openai.AsyncOpenAI object at 0x11c571c90> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a subset of artificial intelligence technologies that are designed to generate new content. Rather than merely analyzing or responding to existing data in a static manner, generative AI models create new data that resembles the data they were trained on. This includes generating text, images, music, and even video.\\n\\nKey technologies and techniques used in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These are a type of neural network architecture where two networks (a generator and a discriminator) are pitted against each other. The generator creates content, while the discriminator evaluates it against real data to improve the generator's output quality over time.\\n\\n2. **Variational Autoencoders (VAEs):** These are used to learn efficient data representations, often for the purpose of generating new data instances similar to the input data.\\n\\n3. **Transformer Models:** These models, which include GPT (Generative Pre-trained Transformer) and its successors, are particularly well-suited for tasks involving sequential data, such as text. They can generate coherent and contextually relevant sequences, making them popular for tasks like text generation, translation, and summarization.\\n\\n4. **Diffusion Models:** These are used for generating high-quality images and have become popular for their ability to produce photorealistic images.\\n\\nGenerative AI has a wide range of applications, including content creation, design, entertainment, and even healthcare, where it can be used to simulate potential drug compounds or model complex biological processes. However, it also raises ethical concerns around authenticity, copyright, and the potential for misuse in generating misleading or harmful content.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 327, 'prompt_tokens': 13, 'total_tokens': 340, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-Bvp7xMNsGPGMfERB7vFg4FtGJyfK2', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--bcd5baa3-7ede-41f2-b2e1-27627b1f560c-0' usage_metadata={'input_tokens': 13, 'output_tokens': 327, 'total_tokens': 340, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith is a tool developed by LangChain, designed to facilitate the development and optimization of applications that leverage language models. It provides a suite of features that enhance the efficiency of building, testing, and monitoring these applications. Key functionalities include:\\n\\n1. **Experimentation and Tracing**: Langsmith allows developers to run multiple experiments to see how different language models perform, offering detailed traceability. This helps in understanding and optimizing the various components of the application.\\n\\n2. **Evaluation and Metrics**: It offers tools to evaluate the performance of language models and measure key metrics to ensure that the application is functioning as intended. This includes the ability to track and compare model outputs across different scenarios.\\n\\n3. **Iterative Feedback and Monitoring**: The platform provides capabilities for continuous monitoring and feedback integration, allowing developers to refine their models based on real-time data and interactions, leading to more robust and reliable applications.\\n\\n4. **Integration with LangChain**: As part of the LangChain ecosystem, Langsmith integrates seamlessly with LangChain's framework, making it easier for developers to incorporate its features into their existing workflows.\\n\\nOverall, Langsmith aims to streamline the process of developing language model-based applications by providing essential tools for experimentation, evaluation, and monitoring.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 249, 'prompt_tokens': 33, 'total_tokens': 282, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-Bvp86gia0kqqhGNwewIVi7kcJHT33', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f4863d89-c3b4-4a27-a075-3eb5cdba5c35-0' usage_metadata={'input_tokens': 33, 'output_tokens': 249, 'total_tokens': 282, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool developed by LangChain designed to enhance the capabilities of agents working with large language models. It focuses on tracing, debugging, and improving these agents, especially in scenarios involving complex chains and sequences of operations. Langsmith offers a suite of features that includes advanced instrumentation to understand how agents process information, tools to identify and fix potential issues, and methods to optimize overall performance.\n",
      "\n",
      "Key features of Langsmith include:\n",
      "\n",
      "1. **Tracing**: Langsmith allows developers to trace the execution path of language model agents. This helps in visualizing and understanding how the agent processes different inputs and executes tasks.\n",
      "\n",
      "2. **Debugging**: The tool provides capabilities to debug issues by highlighting where things might be going wrong in the process. This includes spotting logical errors or inefficiencies in the chain.\n",
      "\n",
      "3. **Evaluation**: Langsmith supports rigorous testing and evaluation of language model outputs. It helps in assessing performance based on various criteria to ensure reliability and accuracy.\n",
      "\n",
      "4. **Optimization**: By offering insights into the execution and performance, Langsmith aids in optimizing agents for better efficiency and performance in real-world applications.\n",
      "\n",
      "5. **Metrics and Monitoring**: Langsmith includes features to monitor ongoing performance and metrics of language models, providing a continuous feedback loop for improvement.\n",
      "\n",
      "Overall, Langsmith is an important tool for developers who are looking to enhance their work with language models, ensuring robustness, efficiency, and effectiveness in deployment scenarios.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_krish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
